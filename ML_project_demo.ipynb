{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_project_demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jny9CGNw1Rjn"
      },
      "source": [
        "# Lifespan Age Transformation Synthesis Demo\n",
        "\n",
        "This Colab notebook demonstrates the capabilities of the GAN architecture proposed in our paper. \n",
        "\n",
        "This colab lets you try our method on your own image!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhbnEdCV2kc-"
      },
      "source": [
        "First, let's download the github repository and install all dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2uubo7PsvxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "927737c4-933f-40d1-892a-dbb0a07036bb"
      },
      "source": [
        "!git clone https://github.com/AbuAbdULLAH-MuhammadAli/FaceAgingStyleGANs\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FaceAgingStyleGANs'...\n",
            "remote: Enumerating objects: 65, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 65 (delta 10), reused 63 (delta 8), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (65/65), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd FaceAgingStyleGANs/\n",
        "!pip3 install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3L3tI3HSW1T",
        "outputId": "bdf3db63-1709-48e6-87b3-c3c54a39e88d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FaceAgingStyleGANs\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (4.1.2.30)\n",
            "Collecting visdom\n",
            "  Downloading visdom-0.1.8.9.tar.gz (676 kB)\n",
            "\u001b[K     |████████████████████████████████| 676 kB 12.4 MB/s \n",
            "\u001b[?25hCollecting dominate\n",
            "  Downloading dominate-2.6.0-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (7.1.2)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 47.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (4.62.3)\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (19.18.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom->-r requirements.txt (line 2)) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom->-r requirements.txt (line 2)) (22.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from visdom->-r requirements.txt (line 2)) (1.15.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n",
            "Collecting torchfile\n",
            "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 8)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 8)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 8)) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 8)) (2.10)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Building wheels for collected packages: visdom, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-py3-none-any.whl size=655250 sha256=47f5ef3464ced7e4d9074722d6f3bdf48d57de6a8264aff1b5a245316c5cdc3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/d1/9b/cde923274eac9cbb6ff0d8c7c72fe30a3da9095a38fd50bbf1\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5709 sha256=eb649a6a45bbbfbde562d74a8219810b6491e7b8338cc77b97d62e8f38195667\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/5c/3a/a80e1c65880945c71fd833408cd1e9a8cb7e2f8f37620bb75b\n",
            "Successfully built visdom torchfile\n",
            "Installing collected packages: jsonpointer, websocket-client, torchfile, jsonpatch, visdom, unidecode, dominate\n",
            "Successfully installed dominate-2.6.0 jsonpatch-1.32 jsonpointer-2.2 torchfile-0.1.0 unidecode-1.3.2 visdom-0.1.8.9 websocket-client-1.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKKNh_xl3AI2"
      },
      "source": [
        "Now let's download the pretrained models for males and females."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ezAOkaHw4Q_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43ffcedd-7cc6-4a06-cc70-60a0d7bd4a06"
      },
      "source": [
        "!python download_models.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading males model\n",
            "100% 213M/213M [00:03<00:00, 56.4MB/s]\n",
            "Extracting males model zip file\n",
            "Done!\n",
            "Downloading females model\n",
            "100% 213M/213M [00:03<00:00, 61.5MB/s]\n",
            "Extracting females model zip file\n",
            "Done!\n",
            "Downloading face landmarks shape predictor\n",
            "100% 99.7M/99.7M [00:06<00:00, 16.6MB/s]\n",
            "Done!\n",
            "Downloading DeeplabV3 backbone Resnet Model parameters\n",
            "100% 178M/178M [00:02<00:00, 70.5MB/s]\n",
            "Done!\n",
            "Downloading DeeplabV3 Model parameters\n",
            "100% 464M/464M [00:06<00:00, 68.2MB/s]\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKl8INdX3IHv"
      },
      "source": [
        "Here, we import libraries and set options."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQKoh2xrw697",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af09255e-e6f6-4c49-f8e3-f4c329828935"
      },
      "source": [
        "import os\n",
        "from collections import OrderedDict\n",
        "from options.test_options import TestOptions\n",
        "from data.data_loader import CreateDataLoader\n",
        "from models.models import create_model\n",
        "import util.util as util\n",
        "from util.visualizer import Visualizer\n",
        "\n",
        "opt = TestOptions().parse(save=False)\n",
        "opt.display_id = 0 # do not launch visdom\n",
        "opt.nThreads = 1   # test code only supports nThreads = 1\n",
        "opt.batchSize = 1  # test code only supports batchSize = 1\n",
        "opt.serial_batches = True  # no shuffle\n",
        "opt.no_flip = True  # no flip\n",
        "opt.in_the_wild = True # This triggers preprocessing of in the wild images in the dataloader\n",
        "opt.traverse = True # This tells the model to traverse the latent space between anchor classes\n",
        "opt.interp_step = 0.05 # this controls the number of images to interpolate between anchor classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------ Options -------------\n",
            "activation: lrelu\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "compare_to_trained_class: 1\n",
            "compare_to_trained_outputs: False\n",
            "conv_weight_norm: True\n",
            "dataroot: ./datasets/males/\n",
            "debug_mode: False\n",
            "decoder_norm: pixel\n",
            "deploy: False\n",
            "display_id: 1\n",
            "display_port: 8097\n",
            "display_single_pane_ncols: 6\n",
            "display_winsize: 256\n",
            "fineSize: 256\n",
            "full_progression: False\n",
            "gen_dim_per_style: 50\n",
            "gpu_ids: [0]\n",
            "how_many: 50\n",
            "id_enc_norm: pixel\n",
            "image_path_file: None\n",
            "in_the_wild: False\n",
            "input_nc: 3\n",
            "interp_step: 0.5\n",
            "isTrain: False\n",
            "loadSize: 256\n",
            "make_video: False\n",
            "max_dataset_size: inf\n",
            "nThreads: 4\n",
            "n_adaptive_blocks: 4\n",
            "n_downsample: 2\n",
            "name: debug\n",
            "ngf: 64\n",
            "no_cond_noise: False\n",
            "no_flip: False\n",
            "no_moving_avg: False\n",
            "normalize_mlp: True\n",
            "ntest: inf\n",
            "output_nc: 3\n",
            "phase: test\n",
            "random_seed: -1\n",
            "resize_or_crop: resize_and_crop\n",
            "results_dir: ./results/\n",
            "serial_batches: False\n",
            "sort_classes: True\n",
            "sort_order: ['0-2', '3-6', '7-9', '15-19', '30-39', '50-69']\n",
            "trained_class_jump: 1\n",
            "traverse: False\n",
            "use_modulated_conv: True\n",
            "use_resblk_pixel_norm: False\n",
            "verbose: False\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--name NAME] [--gpu_ids GPU_IDS]\n",
            "                             [--checkpoints_dir CHECKPOINTS_DIR]\n",
            "                             [--batchSize BATCHSIZE] [--loadSize LOADSIZE]\n",
            "                             [--fineSize FINESIZE] [--input_nc INPUT_NC]\n",
            "                             [--output_nc OUTPUT_NC] [--dataroot DATAROOT]\n",
            "                             [--sort_classes SORT_CLASSES]\n",
            "                             [--sort_order SORT_ORDER]\n",
            "                             [--resize_or_crop RESIZE_OR_CROP]\n",
            "                             [--serial_batches] [--no_flip]\n",
            "                             [--nThreads NTHREADS]\n",
            "                             [--max_dataset_size MAX_DATASET_SIZE]\n",
            "                             [--display_single_pane_ncols DISPLAY_SINGLE_PANE_NCOLS]\n",
            "                             [--display_winsize DISPLAY_WINSIZE]\n",
            "                             [--display_port DISPLAY_PORT]\n",
            "                             [--display_id DISPLAY_ID]\n",
            "                             [--use_modulated_conv USE_MODULATED_CONV]\n",
            "                             [--conv_weight_norm CONV_WEIGHT_NORM]\n",
            "                             [--id_enc_norm ID_ENC_NORM]\n",
            "                             [--decoder_norm {pixel,none}]\n",
            "                             [--n_adaptive_blocks N_ADAPTIVE_BLOCKS]\n",
            "                             [--activation {relu,lrelu}]\n",
            "                             [--normalize_mlp NORMALIZE_MLP] [--no_moving_avg]\n",
            "                             [--use_resblk_pixel_norm] [--ngf NGF]\n",
            "                             [--no_cond_noise]\n",
            "                             [--gen_dim_per_style GEN_DIM_PER_STYLE]\n",
            "                             [--n_downsample N_DOWNSAMPLE] [--verbose]\n",
            "                             [--random_seed RANDOM_SEED] [--ntest NTEST]\n",
            "                             [--results_dir RESULTS_DIR] [--phase PHASE]\n",
            "                             [--which_epoch WHICH_EPOCH] [--how_many HOW_MANY]\n",
            "                             [--in_the_wild] [--traverse] [--full_progression]\n",
            "                             [--make_video] [--compare_to_trained_outputs]\n",
            "                             [--compare_to_trained_class COMPARE_TO_TRAINED_CLASS]\n",
            "                             [--trained_class_jump {1,2}]\n",
            "                             [--interp_step INTERP_STEP] [--deploy]\n",
            "                             [--image_path_file IMAGE_PATH_FILE]\n",
            "                             [--debug_mode]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-377459db-b392-4e8f-9a41-507cf7774702.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLOiDzgKtYyi"
      },
      "source": [
        "Don't worry about this message above, \n",
        "```\n",
        "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-c9d47a98-bdba-4a5f-9f0a-e1437c7228b6.json\n",
        "```\n",
        "everything is perfectly fine..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AFlzSi41Kzg"
      },
      "source": [
        "Next on, we call the data loader and the visualizer class that generates the video from the network outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxBYeTB18zkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5c262eb-d4be-4d72-9cbd-355449716499"
      },
      "source": [
        "data_loader = CreateDataLoader(opt)\n",
        "dataset = data_loader.load_data()\n",
        "visualizer = Visualizer(opt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AgingDataLoader\n",
            "dataset [MulticlassUnalignedDataset] was created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AbUVdK74G5p"
      },
      "source": [
        "Here, we define our model.\n",
        "\n",
        "NOTE: if you plan to try the method for a female, change opt.name to 'females_model'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_0RChfq0YPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "220bcfb1-13f0-4771-f05a-8729d1118778"
      },
      "source": [
        "opt.name = 'males_model' # change to 'females_model' if you're trying the code on a female image\n",
        "model = create_model(opt)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator(\n",
            "  (id_encoder): IdentityEncoder(\n",
            "    (encoder): Sequential(\n",
            "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "      (1): EqualConv2d(\n",
            "        (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "      )\n",
            "      (2): PixelNorm()\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "      (5): EqualConv2d(\n",
            "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
            "      )\n",
            "      (6): PixelNorm()\n",
            "      (7): ReLU(inplace=True)\n",
            "      (8): ReflectionPad2d((1, 1, 1, 1))\n",
            "      (9): EqualConv2d(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
            "      )\n",
            "      (10): PixelNorm()\n",
            "      (11): ReLU(inplace=True)\n",
            "      (12): ResnetBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "          (1): EqualConv2d(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "          )\n",
            "          (2): PixelNorm()\n",
            "          (3): ReLU(inplace=True)\n",
            "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "          (5): EqualConv2d(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "          )\n",
            "          (6): PixelNorm()\n",
            "        )\n",
            "      )\n",
            "      (13): ResnetBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "          (1): EqualConv2d(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "          )\n",
            "          (2): PixelNorm()\n",
            "          (3): ReLU(inplace=True)\n",
            "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "          (5): EqualConv2d(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "          )\n",
            "          (6): PixelNorm()\n",
            "        )\n",
            "      )\n",
            "      (14): ResnetBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "          (1): EqualConv2d(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "          )\n",
            "          (2): PixelNorm()\n",
            "          (3): ReLU(inplace=True)\n",
            "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "          (5): EqualConv2d(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "          )\n",
            "          (6): PixelNorm()\n",
            "        )\n",
            "      )\n",
            "      (15): ResnetBlock(\n",
            "        (conv_block): Sequential(\n",
            "          (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "          (1): EqualConv2d(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "          )\n",
            "          (2): PixelNorm()\n",
            "          (3): ReLU(inplace=True)\n",
            "          (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "          (5): EqualConv2d(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "          )\n",
            "          (6): PixelNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (age_encoder): AgeEncoder(\n",
            "    (encoder): Sequential(\n",
            "      (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "      (1): EqualConv2d(\n",
            "        (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "      )\n",
            "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (3): ReflectionPad2d((1, 1, 1, 1))\n",
            "      (4): EqualConv2d(\n",
            "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
            "      )\n",
            "      (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (6): ReflectionPad2d((1, 1, 1, 1))\n",
            "      (7): EqualConv2d(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
            "      )\n",
            "      (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (9): ReflectionPad2d((1, 1, 1, 1))\n",
            "      (10): EqualConv2d(\n",
            "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))\n",
            "      )\n",
            "      (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (12): ReflectionPad2d((1, 1, 1, 1))\n",
            "      (13): EqualConv2d(\n",
            "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2))\n",
            "      )\n",
            "      (14): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (15): EqualConv2d(\n",
            "        (conv): Conv2d(1024, 300, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): StyledDecoder(\n",
            "    (StyledConvBlock_0): StyledConvBlock(\n",
            "      (conv0): ModulatedConv2d(\n",
            "        (mlp_class_std): Sequential(\n",
            "          (0): EqualLinear(\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (1): PixelNorm()\n",
            "        )\n",
            "        (blur): Blur()\n",
            "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
            "      )\n",
            "      (pxl_norm0): PixelNorm()\n",
            "      (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (conv1): ModulatedConv2d(\n",
            "        (mlp_class_std): Sequential(\n",
            "          (0): EqualLinear(\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (1): PixelNorm()\n",
            "        )\n",
            "        (blur): Blur()\n",
            "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
            "      )\n",
            "      (pxl_norm1): PixelNorm()\n",
            "      (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    )\n",
            "    (StyledConvBlock_1): StyledConvBlock(\n",
            "      (conv0): ModulatedConv2d(\n",
            "        (mlp_class_std): Sequential(\n",
            "          (0): EqualLinear(\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (1): PixelNorm()\n",
            "        )\n",
            "        (blur): Blur()\n",
            "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
            "      )\n",
            "      (pxl_norm0): PixelNorm()\n",
            "      (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (conv1): ModulatedConv2d(\n",
            "        (mlp_class_std): Sequential(\n",
            "          (0): EqualLinear(\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (1): PixelNorm()\n",
            "        )\n",
            "        (blur): Blur()\n",
            "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
            "      )\n",
            "      (pxl_norm1): PixelNorm()\n",
            "      (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    )\n",
            "    (StyledConvBlock_2): StyledConvBlock(\n",
            "      (conv0): ModulatedConv2d(\n",
            "        (mlp_class_std): Sequential(\n",
            "          (0): EqualLinear(\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (1): PixelNorm()\n",
            "        )\n",
            "        (blur): Blur()\n",
            "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
            "      )\n",
            "      (pxl_norm0): PixelNorm()\n",
            "      (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (conv1): ModulatedConv2d(\n",
            "        (mlp_class_std): Sequential(\n",
            "          (0): EqualLinear(\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (1): PixelNorm()\n",
            "        )\n",
            "        (blur): Blur()\n",
            "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
            "      )\n",
            "      (pxl_norm1): PixelNorm()\n",
            "      (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    )\n",
            "    (StyledConvBlock_3): StyledConvBlock(\n",
            "      (conv0): ModulatedConv2d(\n",
            "        (mlp_class_std): Sequential(\n",
            "          (0): EqualLinear(\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (1): PixelNorm()\n",
            "        )\n",
            "        (blur): Blur()\n",
            "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
            "      )\n",
            "      (pxl_norm0): PixelNorm()\n",
            "      (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (conv1): ModulatedConv2d(\n",
            "        (mlp_class_std): Sequential(\n",
            "          (0): EqualLinear(\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (1): PixelNorm()\n",
            "        )\n",
            "        (blur): Blur()\n",
            "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
            "      )\n",
            "      (pxl_norm1): PixelNorm()\n",
            "      (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    )\n",
            "    (StyledConvBlock_up0): StyledConvBlock(\n",
            "      (conv0): ModulatedConv2d(\n",
            "        (mlp_class_std): Sequential(\n",
            "          (0): EqualLinear(\n",
            "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "          )\n",
            "          (1): PixelNorm()\n",
            "        )\n",
            "        (blur): Blur()\n",
            "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (upsampler): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      )\n",
            "      (pxl_norm0): PixelNorm()\n",
            "      (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (conv1): ModulatedConv2d(\n",
            "        (mlp_class_std): Sequential(\n",
            "          (0): EqualLinear(\n",
            "            (linear): Linear(in_features=256, out_features=128, bias=True)\n",
            "          )\n",
            "          (1): PixelNorm()\n",
            "        )\n",
            "        (blur): Blur()\n",
            "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
            "      )\n",
            "      (pxl_norm1): PixelNorm()\n",
            "      (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    )\n",
            "    (StyledConvBlock_up1): StyledConvBlock(\n",
            "      (conv0): ModulatedConv2d(\n",
            "        (mlp_class_std): Sequential(\n",
            "          (0): EqualLinear(\n",
            "            (linear): Linear(in_features=256, out_features=128, bias=True)\n",
            "          )\n",
            "          (1): PixelNorm()\n",
            "        )\n",
            "        (blur): Blur()\n",
            "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (upsampler): Upsample(scale_factor=2.0, mode=nearest)\n",
            "      )\n",
            "      (pxl_norm0): PixelNorm()\n",
            "      (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (conv1): ModulatedConv2d(\n",
            "        (mlp_class_std): Sequential(\n",
            "          (0): EqualLinear(\n",
            "            (linear): Linear(in_features=256, out_features=64, bias=True)\n",
            "          )\n",
            "          (1): PixelNorm()\n",
            "        )\n",
            "        (blur): Blur()\n",
            "        (padding): ReflectionPad2d((1, 1, 1, 1))\n",
            "      )\n",
            "      (pxl_norm1): PixelNorm()\n",
            "      (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    )\n",
            "    (conv_img): Sequential(\n",
            "      (0): EqualConv2d(\n",
            "        (conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (1): Tanh()\n",
            "    )\n",
            "    (mlp): MLP(\n",
            "      (model): Sequential(\n",
            "        (0): PixelNorm()\n",
            "        (1): EqualLinear(\n",
            "          (linear): Linear(in_features=300, out_features=256, bias=True)\n",
            "        )\n",
            "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "        (3): PixelNorm()\n",
            "        (4): EqualLinear(\n",
            "          (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "        (6): PixelNorm()\n",
            "        (7): EqualLinear(\n",
            "          (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "        (9): PixelNorm()\n",
            "        (10): EqualLinear(\n",
            "          (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "        (12): PixelNorm()\n",
            "        (13): EqualLinear(\n",
            "          (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (14): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "        (15): PixelNorm()\n",
            "        (16): EqualLinear(\n",
            "          (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (17): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "        (18): PixelNorm()\n",
            "        (19): EqualLinear(\n",
            "          (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (20): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "        (21): PixelNorm()\n",
            "        (22): EqualLinear(\n",
            "          (linear): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (23): PixelNorm()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InferenceModel(\n",
              "  (netG): Generator(\n",
              "    (id_encoder): IdentityEncoder(\n",
              "      (encoder): Sequential(\n",
              "        (0): ReflectionPad2d((3, 3, 3, 3))\n",
              "        (1): EqualConv2d(\n",
              "          (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
              "        )\n",
              "        (2): PixelNorm()\n",
              "        (3): ReLU(inplace=True)\n",
              "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
              "        (5): EqualConv2d(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
              "        )\n",
              "        (6): PixelNorm()\n",
              "        (7): ReLU(inplace=True)\n",
              "        (8): ReflectionPad2d((1, 1, 1, 1))\n",
              "        (9): EqualConv2d(\n",
              "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
              "        )\n",
              "        (10): PixelNorm()\n",
              "        (11): ReLU(inplace=True)\n",
              "        (12): ResnetBlock(\n",
              "          (conv_block): Sequential(\n",
              "            (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "            (1): EqualConv2d(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "            (2): PixelNorm()\n",
              "            (3): ReLU(inplace=True)\n",
              "            (4): ReflectionPad2d((1, 1, 1, 1))\n",
              "            (5): EqualConv2d(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "            (6): PixelNorm()\n",
              "          )\n",
              "        )\n",
              "        (13): ResnetBlock(\n",
              "          (conv_block): Sequential(\n",
              "            (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "            (1): EqualConv2d(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "            (2): PixelNorm()\n",
              "            (3): ReLU(inplace=True)\n",
              "            (4): ReflectionPad2d((1, 1, 1, 1))\n",
              "            (5): EqualConv2d(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "            (6): PixelNorm()\n",
              "          )\n",
              "        )\n",
              "        (14): ResnetBlock(\n",
              "          (conv_block): Sequential(\n",
              "            (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "            (1): EqualConv2d(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "            (2): PixelNorm()\n",
              "            (3): ReLU(inplace=True)\n",
              "            (4): ReflectionPad2d((1, 1, 1, 1))\n",
              "            (5): EqualConv2d(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "            (6): PixelNorm()\n",
              "          )\n",
              "        )\n",
              "        (15): ResnetBlock(\n",
              "          (conv_block): Sequential(\n",
              "            (0): ReflectionPad2d((1, 1, 1, 1))\n",
              "            (1): EqualConv2d(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "            (2): PixelNorm()\n",
              "            (3): ReLU(inplace=True)\n",
              "            (4): ReflectionPad2d((1, 1, 1, 1))\n",
              "            (5): EqualConv2d(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "            )\n",
              "            (6): PixelNorm()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (age_encoder): AgeEncoder(\n",
              "      (encoder): Sequential(\n",
              "        (0): ReflectionPad2d((3, 3, 3, 3))\n",
              "        (1): EqualConv2d(\n",
              "          (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
              "        )\n",
              "        (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "        (3): ReflectionPad2d((1, 1, 1, 1))\n",
              "        (4): EqualConv2d(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
              "        )\n",
              "        (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "        (6): ReflectionPad2d((1, 1, 1, 1))\n",
              "        (7): EqualConv2d(\n",
              "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
              "        )\n",
              "        (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "        (9): ReflectionPad2d((1, 1, 1, 1))\n",
              "        (10): EqualConv2d(\n",
              "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2))\n",
              "        )\n",
              "        (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "        (12): ReflectionPad2d((1, 1, 1, 1))\n",
              "        (13): EqualConv2d(\n",
              "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2))\n",
              "        )\n",
              "        (14): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "        (15): EqualConv2d(\n",
              "          (conv): Conv2d(1024, 300, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): StyledDecoder(\n",
              "      (StyledConvBlock_0): StyledConvBlock(\n",
              "        (conv0): ModulatedConv2d(\n",
              "          (mlp_class_std): Sequential(\n",
              "            (0): EqualLinear(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "            )\n",
              "            (1): PixelNorm()\n",
              "          )\n",
              "          (blur): Blur()\n",
              "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
              "        )\n",
              "        (pxl_norm0): PixelNorm()\n",
              "        (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "        (conv1): ModulatedConv2d(\n",
              "          (mlp_class_std): Sequential(\n",
              "            (0): EqualLinear(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "            )\n",
              "            (1): PixelNorm()\n",
              "          )\n",
              "          (blur): Blur()\n",
              "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
              "        )\n",
              "        (pxl_norm1): PixelNorm()\n",
              "        (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (StyledConvBlock_1): StyledConvBlock(\n",
              "        (conv0): ModulatedConv2d(\n",
              "          (mlp_class_std): Sequential(\n",
              "            (0): EqualLinear(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "            )\n",
              "            (1): PixelNorm()\n",
              "          )\n",
              "          (blur): Blur()\n",
              "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
              "        )\n",
              "        (pxl_norm0): PixelNorm()\n",
              "        (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "        (conv1): ModulatedConv2d(\n",
              "          (mlp_class_std): Sequential(\n",
              "            (0): EqualLinear(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "            )\n",
              "            (1): PixelNorm()\n",
              "          )\n",
              "          (blur): Blur()\n",
              "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
              "        )\n",
              "        (pxl_norm1): PixelNorm()\n",
              "        (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (StyledConvBlock_2): StyledConvBlock(\n",
              "        (conv0): ModulatedConv2d(\n",
              "          (mlp_class_std): Sequential(\n",
              "            (0): EqualLinear(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "            )\n",
              "            (1): PixelNorm()\n",
              "          )\n",
              "          (blur): Blur()\n",
              "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
              "        )\n",
              "        (pxl_norm0): PixelNorm()\n",
              "        (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "        (conv1): ModulatedConv2d(\n",
              "          (mlp_class_std): Sequential(\n",
              "            (0): EqualLinear(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "            )\n",
              "            (1): PixelNorm()\n",
              "          )\n",
              "          (blur): Blur()\n",
              "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
              "        )\n",
              "        (pxl_norm1): PixelNorm()\n",
              "        (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (StyledConvBlock_3): StyledConvBlock(\n",
              "        (conv0): ModulatedConv2d(\n",
              "          (mlp_class_std): Sequential(\n",
              "            (0): EqualLinear(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "            )\n",
              "            (1): PixelNorm()\n",
              "          )\n",
              "          (blur): Blur()\n",
              "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
              "        )\n",
              "        (pxl_norm0): PixelNorm()\n",
              "        (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "        (conv1): ModulatedConv2d(\n",
              "          (mlp_class_std): Sequential(\n",
              "            (0): EqualLinear(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "            )\n",
              "            (1): PixelNorm()\n",
              "          )\n",
              "          (blur): Blur()\n",
              "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
              "        )\n",
              "        (pxl_norm1): PixelNorm()\n",
              "        (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (StyledConvBlock_up0): StyledConvBlock(\n",
              "        (conv0): ModulatedConv2d(\n",
              "          (mlp_class_std): Sequential(\n",
              "            (0): EqualLinear(\n",
              "              (linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "            )\n",
              "            (1): PixelNorm()\n",
              "          )\n",
              "          (blur): Blur()\n",
              "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (upsampler): Upsample(scale_factor=2.0, mode=nearest)\n",
              "        )\n",
              "        (pxl_norm0): PixelNorm()\n",
              "        (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "        (conv1): ModulatedConv2d(\n",
              "          (mlp_class_std): Sequential(\n",
              "            (0): EqualLinear(\n",
              "              (linear): Linear(in_features=256, out_features=128, bias=True)\n",
              "            )\n",
              "            (1): PixelNorm()\n",
              "          )\n",
              "          (blur): Blur()\n",
              "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
              "        )\n",
              "        (pxl_norm1): PixelNorm()\n",
              "        (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (StyledConvBlock_up1): StyledConvBlock(\n",
              "        (conv0): ModulatedConv2d(\n",
              "          (mlp_class_std): Sequential(\n",
              "            (0): EqualLinear(\n",
              "              (linear): Linear(in_features=256, out_features=128, bias=True)\n",
              "            )\n",
              "            (1): PixelNorm()\n",
              "          )\n",
              "          (blur): Blur()\n",
              "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
              "          (upsampler): Upsample(scale_factor=2.0, mode=nearest)\n",
              "        )\n",
              "        (pxl_norm0): PixelNorm()\n",
              "        (actvn0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "        (conv1): ModulatedConv2d(\n",
              "          (mlp_class_std): Sequential(\n",
              "            (0): EqualLinear(\n",
              "              (linear): Linear(in_features=256, out_features=64, bias=True)\n",
              "            )\n",
              "            (1): PixelNorm()\n",
              "          )\n",
              "          (blur): Blur()\n",
              "          (padding): ReflectionPad2d((1, 1, 1, 1))\n",
              "        )\n",
              "        (pxl_norm1): PixelNorm()\n",
              "        (actvn1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "      )\n",
              "      (conv_img): Sequential(\n",
              "        (0): EqualConv2d(\n",
              "          (conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Tanh()\n",
              "      )\n",
              "      (mlp): MLP(\n",
              "        (model): Sequential(\n",
              "          (0): PixelNorm()\n",
              "          (1): EqualLinear(\n",
              "            (linear): Linear(in_features=300, out_features=256, bias=True)\n",
              "          )\n",
              "          (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "          (3): PixelNorm()\n",
              "          (4): EqualLinear(\n",
              "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "          (6): PixelNorm()\n",
              "          (7): EqualLinear(\n",
              "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "          (9): PixelNorm()\n",
              "          (10): EqualLinear(\n",
              "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "          (12): PixelNorm()\n",
              "          (13): EqualLinear(\n",
              "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (14): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "          (15): PixelNorm()\n",
              "          (16): EqualLinear(\n",
              "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (17): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "          (18): PixelNorm()\n",
              "          (19): EqualLinear(\n",
              "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (20): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "          (21): PixelNorm()\n",
              "          (22): EqualLinear(\n",
              "            (linear): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (23): PixelNorm()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APhLIBEg4gnk"
      },
      "source": [
        "OK, it's time to upload your image.\n",
        "\n",
        "For best results, use images according to the following guidelines:\n",
        "\n",
        "1. The image should contain a single face.\n",
        "2. Image was taken from a digital camera (phone cameras are fine). Old images from film cameras would produce low quality results.\n",
        "3. Pure RGB images only. No black & white, grayscale, sepia, or filtered images (e.g. Instagram filters).\n",
        "4. Person's head should directly face the camera. Looking sideways/downwards/upwards degrades the results.\n",
        "5. The person's face should not be occluded (or partially occluded) by any item.\n",
        "6. Both eyes should be open and visible. (eyeglasses are ok, no sunglasses)\n",
        "\n",
        "Your uploaded images are local to the Colab instance and are not accessible by the paper authors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSUbmd697Api",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "fa5819d3-0a34-414f-adcd-a374b27dd22c"
      },
      "source": [
        "# upload your image (the code supports only a single image at a time)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "  img_path = filename\n",
        "  print('User uploaded file \"{name}\"'.format(name=filename))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e055bd8b-b402-4e86-a223-8cc812788b35\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e055bd8b-b402-4e86-a223-8cc812788b35\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 59350652_2038198296307253_8953375459026927616_o (2).jpg to 59350652_2038198296307253_8953375459026927616_o (2).jpg\n",
            "User uploaded file \"59350652_2038198296307253_8953375459026927616_o (2).jpg\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgxXQ4tu45V5"
      },
      "source": [
        "Finally, we preprocess the image, run the network, and save the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ3Az0VY3Fwt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "94382d8c-9cd1-4051-cc5f-97ee8a067c05"
      },
      "source": [
        "data = dataset.dataset.get_item_from_path(img_path)\n",
        "visuals = model.inference(data)\n",
        "\n",
        "os.makedirs('results', exist_ok=True)\n",
        "out_path = os.path.join('results', os.path.splitext(img_path)[0].replace(' ', '_') + '.mp4')\n",
        "visualizer.make_video(visuals, out_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-cdd89bd80794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_item_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvisuals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mout_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Lifespan_Age_Transformation_Synthesis/models/LATS_model.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_conditions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_conditions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeploy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterp_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumClasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Lifespan_Age_Transformation_Synthesis/models/networks.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, input, target_age_features, traverse, deploy, interp_step)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_age_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeploy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0mid_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_age_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeploy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterp_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Lifespan_Age_Transformation_Synthesis/models/networks.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, id_features, target_age_features, traverse, deploy, interp_step)\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_age_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeploy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_age_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeploy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterp_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Lifespan_Age_Transformation_Synthesis/models/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, id_features, target_age, traverse, deploy, interp_step)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStyledConvBlock_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStyledConvBlock_up0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStyledConvBlock_up1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Lifespan_Age_Transformation_Synthesis/models/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, latent)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodulated_conv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Lifespan_Age_Transformation_Synthesis/models/networks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, latent)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/padding.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reflect'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_pad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   4187\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"reflect\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4189\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreflection_pad2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4190\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"replicate\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4191\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplication_pad2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.21 GiB (GPU 0; 11.17 GiB total capacity; 4.48 GiB already allocated; 2.37 GiB free; 8.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRCyM2i65ZdB"
      },
      "source": [
        "Let's display at the results.\n",
        "\n",
        "NOTE: if you're using chrome, uncomment the lines below. For some reason, mp4 files won't display on chrome browser, so we need to convert to webm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwjp6STO3hCz"
      },
      "source": [
        "use_webm = False\n",
        "# For some unknown reason the mp4 video is not displayed on chrome\n",
        "# If you have chrome, uncomment the following lines to convert the \n",
        "# result to webm for display purposes\n",
        "\n",
        "# !pip3 install webm\n",
        "# webm_out_path = os.path.join('results', os.path.splitext(img_path)[0].replace(' ', '_') + '.webm')\n",
        "# !webm -i $out_path $webm_out_path\n",
        "# use_webm = True\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "video_path = webm_out_path if use_webm else out_path\n",
        "video_type = \"video/webm\" if use_webm else \"video/mp4\"\n",
        "mp4 = open(video_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width={0} controls>\n",
        "      <source src=\"{1}\" type=\"{2}\">\n",
        "</video>\n",
        "\"\"\".format(opt.fineSize, data_url, video_type))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RLnTezc59FZ"
      },
      "source": [
        "You can download the result if you want"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W87da7s9FM1"
      },
      "source": [
        "files.download(out_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}